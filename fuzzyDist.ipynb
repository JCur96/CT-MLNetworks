{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzyDist.py\n",
    "## edge list creation script\n",
    "## author: J Curry\n",
    "## date: 09/03/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fishc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#from fuzzywuzzy import fuzz\n",
    "#from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## might not need these??\n",
    "import random\n",
    "import gc \n",
    "import timeit\n",
    "import sys\n",
    "from datetime import datetime as dt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "#%pip install sparse_dot_topn \n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ref_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>A computer-assisted system for photographic m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>25 (11), pp. 120-126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>(2008) An Analysis of Utilizing the Leatherba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>Application of a method for individual photog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>Spatial heterogeneity in the effects of clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351098</th>\n",
       "      <td>351281</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>(1996) Measuring and monitoring biological di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351099</th>\n",
       "      <td>351282</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Acoustic monitoring for conservation in tropi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351100</th>\n",
       "      <td>351283</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Monitoring of biological diversity in space a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351101</th>\n",
       "      <td>351284</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Software to facilitate and streamline camera ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351102</th>\n",
       "      <td>351285</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Introducing a central African primate vocalis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351103 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Index    ID                                              Title  \\\n",
       "0            1     4  APHIS: A new software for photo-matching in ec...   \n",
       "1            2     4  APHIS: A new software for photo-matching in ec...   \n",
       "2            3     4  APHIS: A new software for photo-matching in ec...   \n",
       "3            4     4  APHIS: A new software for photo-matching in ec...   \n",
       "4            5     4  APHIS: A new software for photo-matching in ec...   \n",
       "...        ...   ...                                                ...   \n",
       "351098  351281  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351099  351282  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351100  351283  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351101  351284  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351102  351285  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "\n",
       "                                                ref_title  \n",
       "0        A computer-assisted system for photographic m...  \n",
       "1                                    25 (11), pp. 120-126  \n",
       "2        (2008) An Analysis of Utilizing the Leatherba...  \n",
       "3        Application of a method for individual photog...  \n",
       "4        Spatial heterogeneity in the effects of clima...  \n",
       "...                                                   ...  \n",
       "351098   (1996) Measuring and monitoring biological di...  \n",
       "351099   Acoustic monitoring for conservation in tropi...  \n",
       "351100   Monitoring of biological diversity in space a...  \n",
       "351101   Software to facilitate and streamline camera ...  \n",
       "351102   Introducing a central African primate vocalis...  \n",
       "\n",
       "[351103 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refsDf = pd.read_csv('citationNetworks/Data/SplitRefs.csv')\n",
    "#refsDf['ref_title'] = str(refsDf['ref_title'])\n",
    "refsDf = refsDf[['X','ID','Title', 'ref_title']]\n",
    "refsDf.set_axis(['Index', 'ID','Title', 'ref_title'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesAndIDs = refsDf[['ID','Title']]\n",
    "titlesAndIDs.set_axis(['ID', 'ref_title'], axis=1)\n",
    "refsDf = pd.concat([refsDf, titlesAndIDs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "refsDf['ref_title'] = refsDf['ref_title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "STOPWORDS = set(STOPWORDS)\n",
    "    \n",
    "def text_prepare(text, STOPWORDS):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: a clean string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[\\n\\\"\\'/(){}\\[\\]\\|@,;#]')\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS]) \n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'camera trap type many need? review camera features study designs range wildlife research applications 2013 hystrix 24 pp. 148-156'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_prepare(\" 'Which camera trap type and how many do I need?'' A review of camera features and study designs for a range of wildlife research applications (2013) Hystrix, 24, pp. 148-156\", STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(refsDf['ref_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "refsDf['ref_title'] = refsDf['ref_title'].astype(str)\n",
    "refsDf['ProcessedRef'] = refsDf['ref_title'].apply(lambda x: text_prepare(x, STOPWORDS)) # not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 74915)\t0.20260901979099302\n",
      "  (0, 121137)\t0.22843925365043002\n",
      "  (0, 13794)\t0.26456663913564926\n",
      "  (0, 34994)\t0.29380885380701566\n",
      "  (0, 118448)\t0.30443818371828746\n",
      "  (0, 139623)\t0.3216862752972301\n",
      "  (0, 184753)\t0.31906491304828544\n",
      "  (0, 58897)\t0.31783508266214205\n",
      "  (0, 82572)\t0.1853262187147224\n",
      "  (0, 74898)\t0.16556874718339992\n",
      "  (0, 121025)\t0.15371711278728148\n",
      "  (0, 13526)\t0.1431332628105233\n",
      "  (0, 34962)\t0.15990599849200957\n",
      "  (0, 118445)\t0.24570425606950197\n",
      "  (0, 139609)\t0.2074796567981169\n",
      "  (0, 184647)\t0.18754744752548907\n",
      "  (0, 58890)\t0.28534620289427476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computer-assisted system photographic mark-recapture analysis 2012 methods ecol. evol'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "tf_idf_matrix = tfidf_vectorizer.fit_transform(refsDf['ProcessedRef'])\n",
    "print(tf_idf_matrix[0])\n",
    "refsDf['ProcessedRef'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refsDf['CitingTitle'] = refsDf['Title'].apply(lambda x: text_prepare(x, STOPWORDS))\n",
    "# tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "# tf_idf_matrix1 = tfidf_vectorizer.fit_transform(refsDf['CitingTitle'])\n",
    "\n",
    "# print(tf_idf_matrix1[0])\n",
    "# refsDf['CitingTitle'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "# adjust lower bound: 0.8\n",
    "# keep top 10 similar results\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.8)\n",
    "\n",
    "t = time.time()-t1\n",
    "print(\"finished in:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "\n",
    "# # adjust lower bound: 0.8\n",
    "# # keep top 10 similar results\n",
    "# matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix1, 10, 0.8)\n",
    "\n",
    "# t = time.time()-t1\n",
    "# print(\"finished in:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'ProcessedRef': left_side,\n",
    "                          'SIMILAR_TITLE': right_side,\n",
    "                           'similairity_score': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to think about how to get ID linked to this\n",
    "# obvs ID for all refs should be NA or 0 \n",
    "# Different col for citingID maybe?\n",
    "# ID col for actual papers \n",
    "# or investigate how to do this for two seperate date sets\n",
    "\n",
    "# def get_matches_df1(sparse_matrix, name_vector, top=100):\n",
    "#     non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "#     sparserows = non_zeros[0]\n",
    "#     sparsecols = non_zeros[1]\n",
    "    \n",
    "#     if top:\n",
    "#         nr_matches = top\n",
    "#     else:\n",
    "#         nr_matches = sparsecols.size\n",
    "    \n",
    "#     left_side = np.empty([nr_matches], dtype=object)\n",
    "#     right_side = np.empty([nr_matches], dtype=object)\n",
    "#     similairity = np.zeros(nr_matches)\n",
    "#     ID = np.empty([nr_matches], dtype=object)\n",
    "    \n",
    "#     for index in range(0, nr_matches):\n",
    "#         left_side[index] = name_vector[sparserows[index]]\n",
    "#         right_side[index] = name_vector[sparsecols[index]]\n",
    "#         similairity[index] = sparse_matrix.data[index]\n",
    "#         ID[index] = 1\n",
    "    \n",
    "#     return pd.DataFrame({'ProcessedRef': left_side,\n",
    "#                           'SIMILAR_TITLE': right_side,\n",
    "#                            'similairity_score': similairity,\n",
    "#                            'ID': ID,\n",
    "#                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "702197",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17732\\649313634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmatches_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmatches_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matches_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefsDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ProcessedRef'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Remove all exact matches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmatches_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatches_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatches_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'similairity_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.99999\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmatches_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17732\\2799733783.py\u001b[0m in \u001b[0;36mget_matches_df\u001b[1;34m(sparse_matrix, name_vector, top)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_matches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mleft_side\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msparserows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mright_side\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msparsecols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0msimilairity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4402\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4404\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4405\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 702197"
     ]
    }
   ],
   "source": [
    "matches_df = pd.DataFrame()\n",
    "matches_df = get_matches_df(matches, refsDf['ProcessedRef'], top=10000)\n",
    "# Remove all exact matches\n",
    "matches_df = matches_df[matches_df['similairity_score'] < 0.99999] \n",
    "matches_df.sample(10)\n",
    "matches_df.sort_values(['similairity_score'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches_df = pd.DataFrame()\n",
    "# matches_df = get_matches_df(matches, refsDf['CitingTitle'], top=10000)\n",
    "# # Remove all exact matches\n",
    "# matches_df = matches_df[matches_df['similairity_score'] < 0.99999] \n",
    "# matches_df.sample(10)\n",
    "# matches_df.sort_values(['similairity_score'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refsDf = pd.read_csv('citationNetworks/Data/SplitRefs.csv')\n",
    "#print(refsDf.head())\n",
    "#fuzz.ratio(refsDf[\"Title\"], refsDf[\"Reference\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above basically works, however it is matching only within the single column (so just with titles of references). \n",
    "Potentially this can be solved by adding in the the citing papers titles to this column, with their actual IDs? \n",
    "Might be that from the Index column we can work back to getting the IDs linked back up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to unique \n",
    "# uniqueRefs = refsDf.drop_duplicates(subset=['ref_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(uniqueRefs)):\n",
    "#     title = uniqueRefs.iloc[i,6] # 6 or title\n",
    "#     refTitle = uniqueRefs.iloc[i,7] # 7 or ref title\n",
    "#     ID = uniqueRefs.iloc[i,4] # 4 or ID\n",
    "#     ratio = fuzz.ratio(title, refTitle)\n",
    "#     if ratio > 50:\n",
    "#         #append to a df with title, re_title, ID, ratio\n",
    "#         tmpDf = pd.DataFrame([[ID, title, refTitle, ratio]], columns=list('ID', 'Title', 'RefTitle', 'PercentMatch'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in uniqueRefs.iterrows():\n",
    "#     title = row['Title'] # 6 or title\n",
    "#     refTitle = row['ref_title'] # 7 or ref title\n",
    "#     ID = row['ID'] # 4 or ID\n",
    "#     ratio = fuzz.ratio(title, refTitle)\n",
    "#     # print(ratio)\n",
    "#     # if ratio > 50:\n",
    "#     #     #append to a df with title, re_title, ID, ratio\n",
    "#     #     tmpDf = pd.DataFrame([[ID, title, refTitle, ratio]], columns=list('ID', 'Title', 'RefTitle', 'PercentMatch'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_value = float(\"NaN\")\n",
    "# uniqueRefs = uniqueRefs.replace(\"\", nan_value)\n",
    "# uniqueRefs = uniqueRefs.dropna(subset=[\"ref_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniUniqueRefs = uniqueRefs.iloc[0:10]\n",
    "# titleDf = uniqueRefs = refsDf.drop_duplicates(subset=['Title'])#\n",
    "# #tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "# tmpDf = pd.DataFrame(columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID'))\n",
    "# columns = list(tmpDf)\n",
    "# newDF = []\n",
    "\n",
    "# for index, row in tqdm(miniUniqueRefs.iterrows()):\n",
    "#     title = row['Title'] # 6 or title\n",
    "#     refTitle = str(row['ref_title']) # 7 or ref title\n",
    "#     ID = row['ID'] # 4 or ID\n",
    "#     output = process.extractOne(refTitle, titleDf['Title'], scorer=fuzz.token_sort_ratio)\n",
    "#     # print(output)\n",
    "#     ratio = output[1]\n",
    "#     bestMatch = output[0]\n",
    "#     bestMatchID = output[2]\n",
    "#     values = [ID, title, refTitle, ratio, bestMatch, bestMatchID]\n",
    "#     zipped = zip(columns, values)\n",
    "#     dictionary = dict(zipped)\n",
    "#     newDF.append(dictionary)\n",
    "#     # tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "#     # tmpDf.columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID')\n",
    "#     # tmpDf.append(tmpDf)\n",
    "# print(tmpDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd355fb90a7420f99789f7931751513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# titleDf = uniqueRefs = refsDf.drop_duplicates(subset=['Title'])#\n",
    "# #tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "# tmpDf = pd.DataFrame(columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID'))\n",
    "# columns = list(tmpDf)\n",
    "# newDF = []\n",
    "\n",
    "# #with alive_bar(238148, force_tty=True) as bar:\n",
    "# for index, row in tqdm(uniqueRefs.iterrows()):\n",
    "#     title = row['Title'] # 6 or title\n",
    "#     refTitle = str(row['ref_title']) # 7 or ref title\n",
    "#     ID = row['ID'] # 4 or ID\n",
    "#     output = process.extractOne(refTitle, titleDf['Title'], scorer=fuzz.token_sort_ratio)\n",
    "#     # print(output)\n",
    "#     ratio = output[1]\n",
    "#     bestMatch = output[0]\n",
    "#     bestMatchID = output[2]\n",
    "#     values = [ID, title, refTitle, ratio, bestMatch, bestMatchID]\n",
    "#     zipped = zip(columns, values)\n",
    "#     dictionary = dict(zipped)\n",
    "#     newDF.append(dictionary)\n",
    "#     #tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "#     #tmpDf.columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID')\n",
    "#     #tmpDf.append(tmpDf)\n",
    "# #bar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Can community-protected areas conserve biodiversity in human-modified tropical landscapes? The case of terrestrial mammals in Southern Mexico [Aires protégées communautaires peuvent conserver la biodiversité dans les paysages tropicaux modifiés par l'homme? Le cas des mammifères terrestres dans le sud du Mexique.] [New população e extensão do alcance do macaco-aranha marrom-headed equatoriana Criticamente em Perigo (Ateles fusciceps fusciceps) no oeste do Equador] [¿Pueden las áreas protegidas en la comunidad conservar la biodiversidad en paisajes tropicales modificados por el hombre-? El caso de los mamíferos terrestres en el sur de México.]\", 38)\n"
     ]
    }
   ],
   "source": [
    "# miniUniqueRefs = uniqueRefs.iloc[0:10]\n",
    "# df0_names = list(miniUniqueRefs.ref_title.unique())\n",
    "# df1_names = list(uniqueRefs.ref_title.unique())\n",
    "# df2_names = list(uniqueRefs.Title.unique())\n",
    "# print(process.extractOne(str(df0_names), df2_names, scorer=fuzz.token_sort_ratio))\n",
    "# #print(process.extractOne(str(df1_names), df2_names, scorer=fuzz.token_sort_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def match_names(name, list_names, min_score=0):\n",
    "#     max_score = -1\n",
    "#     max_name = ''\n",
    "#     for x in list_names:\n",
    "#         score = fuzz.ratio(name, x)\n",
    "#         if (score > min_score) & (score > max_score):\n",
    "#             max_name = x\n",
    "#             max_score = score\n",
    "#     return (max_name, max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Can community-protected areas conserve biodiversity in human-modified tropical landscapes? The case of terrestrial mammals in Southern Mexico [Aires protégées communautaires peuvent conserver la biodiversité dans les paysages tropicaux modifiés par l'homme? Le cas des mammifères terrestres dans le sud du Mexique.] [New população e extensão do alcance do macaco-aranha marrom-headed equatoriana Criticamente em Perigo (Ateles fusciceps fusciceps) no oeste do Equador] [¿Pueden las áreas protegidas en la comunidad conservar la biodiversidad en paisajes tropicales modificados por el hombre-? El caso de los mamíferos terrestres en el sur de México.]\", 38)\n"
     ]
    }
   ],
   "source": [
    "# df1_names = list(uniqueRefs.ref_title.unique())\n",
    "# titlesList = list(uniqueRefs.Title.unique())\n",
    "# refsAsArray = uniqueRefs.to_numpy()\n",
    "# miniUniqueRefs = uniqueRefs.iloc[0:10]\n",
    "# miniArray = miniUniqueRefs.to_numpy()\n",
    "\n",
    "# print(process.extractOne(str(miniArray[:,5]), titlesList, scorer=fuzz.token_sort_ratio))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b0f069635f502c080d2c86df588aca401f45023c6eba452c7d287578147dabf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
