{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzyDist.py\n",
    "## edge list creation script\n",
    "## author: J Curry\n",
    "## date: 09/03/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fishc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#from fuzzywuzzy import fuzz\n",
    "#from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## might not need these??\n",
    "import random\n",
    "import gc \n",
    "import timeit\n",
    "import sys\n",
    "from datetime import datetime as dt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "#%pip install sparse_dot_topn \n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "import time\n",
    "\n",
    "import ftfy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>ref_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>A computer-assisted system for photographic m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>25 (11), pp. 120-126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>(2008) An Analysis of Utilizing the Leatherba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>Application of a method for individual photog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>APHIS: A new software for photo-matching in ec...</td>\n",
       "      <td>Spatial heterogeneity in the effects of clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351098</th>\n",
       "      <td>351281</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>(1996) Measuring and monitoring biological di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351099</th>\n",
       "      <td>351282</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Acoustic monitoring for conservation in tropi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351100</th>\n",
       "      <td>351283</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Monitoring of biological diversity in space a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351101</th>\n",
       "      <td>351284</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Software to facilitate and streamline camera ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351102</th>\n",
       "      <td>351285</td>\n",
       "      <td>6372</td>\n",
       "      <td>Methods for wildlife monitoring in tropical fo...</td>\n",
       "      <td>Introducing a central African primate vocalis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351103 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Index    ID                                              Title  \\\n",
       "0            1     4  APHIS: A new software for photo-matching in ec...   \n",
       "1            2     4  APHIS: A new software for photo-matching in ec...   \n",
       "2            3     4  APHIS: A new software for photo-matching in ec...   \n",
       "3            4     4  APHIS: A new software for photo-matching in ec...   \n",
       "4            5     4  APHIS: A new software for photo-matching in ec...   \n",
       "...        ...   ...                                                ...   \n",
       "351098  351281  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351099  351282  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351100  351283  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351101  351284  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "351102  351285  6372  Methods for wildlife monitoring in tropical fo...   \n",
       "\n",
       "                                                ref_title  \n",
       "0        A computer-assisted system for photographic m...  \n",
       "1                                    25 (11), pp. 120-126  \n",
       "2        (2008) An Analysis of Utilizing the Leatherba...  \n",
       "3        Application of a method for individual photog...  \n",
       "4        Spatial heterogeneity in the effects of clima...  \n",
       "...                                                   ...  \n",
       "351098   (1996) Measuring and monitoring biological di...  \n",
       "351099   Acoustic monitoring for conservation in tropi...  \n",
       "351100   Monitoring of biological diversity in space a...  \n",
       "351101   Software to facilitate and streamline camera ...  \n",
       "351102   Introducing a central African primate vocalis...  \n",
       "\n",
       "[351103 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refsDf = pd.read_csv('citationNetworks/Data/SplitRefs.csv')\n",
    "#refsDf['ref_title'] = str(refsDf['ref_title'])\n",
    "refsDf = refsDf[['X','ID','Title', 'ref_title']]\n",
    "refsDf.set_axis(['Index', 'ID','Title', 'ref_title'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesAndIDs = refsDf[['ID','Title']]\n",
    "titlesAndIDs.set_axis(['ID', 'ref_title'], axis=1)\n",
    "refsDf = pd.concat([refsDf, titlesAndIDs])\n",
    "refsDf.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#print(refsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "refsDf['ref_title'] = refsDf['ref_title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "STOPWORDS = set(STOPWORDS)\n",
    "    \n",
    "def text_prepare(text, STOPWORDS):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: a clean string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[\\n\\\"\\'/(){}\\[\\]\\|@,;#]')\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS]) \n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'camera trap type many need? review camera features study designs range wildlife research applications 2013 hystrix 24 pp. 148-156'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_prepare(\" 'Which camera trap type and how many do I need?'' A review of camera features and study designs for a range of wildlife research applications (2013) Hystrix, 24, pp. 148-156\", STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(refsDf['ref_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "refsDf['ref_title'] = refsDf['ref_title'].astype(str)\n",
    "refsDf['ProcessedRef'] = refsDf['ref_title'].apply(lambda x: text_prepare(x, STOPWORDS)) # not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 74915)\t0.21195646262231693\n",
      "  (0, 121137)\t0.2325964971431815\n",
      "  (0, 13794)\t0.26146462461044706\n",
      "  (0, 34994)\t0.28483105340733644\n",
      "  (0, 118448)\t0.2933245783787395\n",
      "  (0, 139622)\t0.3071069238095125\n",
      "  (0, 184752)\t0.30501228511578876\n",
      "  (0, 58897)\t0.3040295707600868\n",
      "  (0, 82572)\t0.1981463820488058\n",
      "  (0, 74898)\t0.1823588790524863\n",
      "  (0, 121025)\t0.17288865340932277\n",
      "  (0, 13526)\t0.1644314698595064\n",
      "  (0, 34962)\t0.17783397505396611\n",
      "  (0, 118445)\t0.24639235543357263\n",
      "  (0, 139608)\t0.21584841793765408\n",
      "  (0, 184646)\t0.19992128813685942\n",
      "  (0, 58890)\t0.2780688456810141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computer-assisted system photographic mark-recapture analysis 2012 methods ecol. evol'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "tf_idf_matrix = tfidf_vectorizer.fit_transform(refsDf['ProcessedRef'])\n",
    "print(tf_idf_matrix[0])\n",
    "refsDf['ProcessedRef'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refsDf['CitingTitle'] = refsDf['Title'].apply(lambda x: text_prepare(x, STOPWORDS))\n",
    "# tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "# tf_idf_matrix1 = tfidf_vectorizer.fit_transform(refsDf['CitingTitle'])\n",
    "\n",
    "# print(tf_idf_matrix1[0])\n",
    "# refsDf['CitingTitle'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in: 422.572092294693\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "# adjust lower bound: 0.8\n",
    "# keep top 10 similar results\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.8)\n",
    "\n",
    "t = time.time()-t1\n",
    "print(\"finished in:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "\n",
    "# # adjust lower bound: 0.8\n",
    "# # keep top 10 similar results\n",
    "# matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix1, 10, 0.8)\n",
    "\n",
    "# t = time.time()-t1\n",
    "# print(\"finished in:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'ProcessedRef': left_side,\n",
    "                          'SIMILAR_TITLE': right_side,\n",
    "                           'similairity_score': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to think about how to get ID linked to this\n",
    "# obvs ID for all refs should be NA or 0 \n",
    "# Different col for citingID maybe?\n",
    "# ID col for actual papers \n",
    "# or investigate how to do this for two seperate date sets\n",
    "\n",
    "# def get_matches_df1(sparse_matrix, name_vector, top=100):\n",
    "#     non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "#     sparserows = non_zeros[0]\n",
    "#     sparsecols = non_zeros[1]\n",
    "    \n",
    "#     if top:\n",
    "#         nr_matches = top\n",
    "#     else:\n",
    "#         nr_matches = sparsecols.size\n",
    "    \n",
    "#     left_side = np.empty([nr_matches], dtype=object)\n",
    "#     right_side = np.empty([nr_matches], dtype=object)\n",
    "#     similairity = np.zeros(nr_matches)\n",
    "#     ID = np.empty([nr_matches], dtype=object)\n",
    "    \n",
    "#     for index in range(0, nr_matches):\n",
    "#         left_side[index] = name_vector[sparserows[index]]\n",
    "#         right_side[index] = name_vector[sparsecols[index]]\n",
    "#         similairity[index] = sparse_matrix.data[index]\n",
    "#         ID[index] = 1\n",
    "    \n",
    "#     return pd.DataFrame({'ProcessedRef': left_side,\n",
    "#                           'SIMILAR_TITLE': right_side,\n",
    "#                            'similairity_score': similairity,\n",
    "#                            'ID': ID,\n",
    "#                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProcessedRef</th>\n",
       "      <th>SIMILAR_TITLE</th>\n",
       "      <th>similairity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>i̇lemin gürkan b status activity patterns cara...</td>\n",
       "      <td>status activity patterns caracal caracal carac...</td>\n",
       "      <td>0.994155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>i̇lemin gürkan b status activity patterns cara...</td>\n",
       "      <td>status activity patterns caracal caracal carac...</td>\n",
       "      <td>0.994155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>drones count gulls? minimal disturbance semiau...</td>\n",
       "      <td>drones count gulls? minimal disturbance semiau...</td>\n",
       "      <td>0.992591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7448</th>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>0.991789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>0.991789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>0.991437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276</th>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>0.991437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9275</th>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>0.991437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>0.990425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>0.990425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>0.990425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>0.990412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>0.990412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>0.989674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>0.989674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>“grabcut” - interactive foreground extraction ...</td>\n",
       "      <td>grabcut: interactive foreground extraction usi...</td>\n",
       "      <td>0.988979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>0.987839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>0.987839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>0.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>0.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7896</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>urbanization affects neophilia risk-taking bir...</td>\n",
       "      <td>urbanization affects neophilia risk-taking bir...</td>\n",
       "      <td>0.986727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>emerging technologies conserve biodiversity 20...</td>\n",
       "      <td>emerging technologies conserve biodiversity 20...</td>\n",
       "      <td>0.985619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>trophic scaling occupancy analysis reveals lio...</td>\n",
       "      <td>trophic scaling occupancy analysis reveals lio...</td>\n",
       "      <td>0.985090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6869</th>\n",
       "      <td>using landscape bioclimatic features predict d...</td>\n",
       "      <td>using landscape bioclimatic features predict d...</td>\n",
       "      <td>0.983668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>dieta uso de hábitat patrones de actividad del...</td>\n",
       "      <td>dieta uso de hábitat patrones de actividad del...</td>\n",
       "      <td>0.983313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>dieta uso de hábitat patrones de actividad del...</td>\n",
       "      <td>dieta uso de hábitat patrones de actividad del...</td>\n",
       "      <td>0.983313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ProcessedRef  \\\n",
       "1871  i̇lemin gürkan b status activity patterns cara...   \n",
       "1872  i̇lemin gürkan b status activity patterns cara...   \n",
       "8900  drones count gulls? minimal disturbance semiau...   \n",
       "7448  wolves modulate soil nutrient heterogeneity fo...   \n",
       "7447  wolves modulate soil nutrient heterogeneity fo...   \n",
       "9277  three novel methods estimate abundance unmarke...   \n",
       "9276  three novel methods estimate abundance unmarke...   \n",
       "9275  three novel methods estimate abundance unmarke...   \n",
       "3387  three critical factors affecting automated ima...   \n",
       "3386  three critical factors affecting automated ima...   \n",
       "3388  three critical factors affecting automated ima...   \n",
       "174   remote infrared cameras used differentiate sma...   \n",
       "3475  remote infrared cameras used differentiate sma...   \n",
       "280   camera trapping: contemporary approach monitor...   \n",
       "3581  camera trapping: contemporary approach monitor...   \n",
       "1774  “grabcut” - interactive foreground extraction ...   \n",
       "5787  foraging ecology jaguar panthera onca puma pum...   \n",
       "6248  foraging ecology jaguar panthera onca puma pum...   \n",
       "7431  toad tongue breakfast: exploitation novel prey...   \n",
       "7432  toad tongue breakfast: exploitation novel prey...   \n",
       "1328  toad’s tongue breakfast: exploitation novel pr...   \n",
       "7895  toad’s tongue breakfast: exploitation novel pr...   \n",
       "7896  toad’s tongue breakfast: exploitation novel pr...   \n",
       "1329  toad’s tongue breakfast: exploitation novel pr...   \n",
       "3901  urbanization affects neophilia risk-taking bir...   \n",
       "3110  emerging technologies conserve biodiversity 20...   \n",
       "6966  trophic scaling occupancy analysis reveals lio...   \n",
       "6869  using landscape bioclimatic features predict d...   \n",
       "4097  dieta uso de hábitat patrones de actividad del...   \n",
       "4098  dieta uso de hábitat patrones de actividad del...   \n",
       "\n",
       "                                          SIMILAR_TITLE  similairity_score  \n",
       "1871  status activity patterns caracal caracal carac...           0.994155  \n",
       "1872  status activity patterns caracal caracal carac...           0.994155  \n",
       "8900  drones count gulls? minimal disturbance semiau...           0.992591  \n",
       "7448  wolves modulate soil nutrient heterogeneity fo...           0.991789  \n",
       "7447  wolves modulate soil nutrient heterogeneity fo...           0.991789  \n",
       "9277  three novel methods estimate abundance unmarke...           0.991437  \n",
       "9276  three novel methods estimate abundance unmarke...           0.991437  \n",
       "9275  three novel methods estimate abundance unmarke...           0.991437  \n",
       "3387  three critical factors affecting automated ima...           0.990425  \n",
       "3386  three critical factors affecting automated ima...           0.990425  \n",
       "3388  three critical factors affecting automated ima...           0.990425  \n",
       "174   remote infrared cameras used differentiate sma...           0.990412  \n",
       "3475  remote infrared cameras used differentiate sma...           0.990412  \n",
       "280   camera trapping: contemporary approach monitor...           0.989674  \n",
       "3581  camera trapping: contemporary approach monitor...           0.989674  \n",
       "1774  grabcut: interactive foreground extraction usi...           0.988979  \n",
       "5787  foraging ecology jaguar panthera onca puma pum...           0.987839  \n",
       "6248  foraging ecology jaguar panthera onca puma pum...           0.987839  \n",
       "7431  toad’s tongue breakfast: exploitation novel pr...           0.987754  \n",
       "7432  toad’s tongue breakfast: exploitation novel pr...           0.987754  \n",
       "1328  toad tongue breakfast: exploitation novel prey...           0.987754  \n",
       "7895  toad tongue breakfast: exploitation novel prey...           0.987754  \n",
       "7896  toad tongue breakfast: exploitation novel prey...           0.987754  \n",
       "1329  toad tongue breakfast: exploitation novel prey...           0.987754  \n",
       "3901  urbanization affects neophilia risk-taking bir...           0.986727  \n",
       "3110  emerging technologies conserve biodiversity 20...           0.985619  \n",
       "6966  trophic scaling occupancy analysis reveals lio...           0.985090  \n",
       "6869  using landscape bioclimatic features predict d...           0.983668  \n",
       "4097  dieta uso de hábitat patrones de actividad del...           0.983313  \n",
       "4098  dieta uso de hábitat patrones de actividad del...           0.983313  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df = pd.DataFrame()\n",
    "matches_df = get_matches_df(matches, refsDf['ProcessedRef'], top=10000)\n",
    "# Remove all exact matches\n",
    "matches_df = matches_df[matches_df['similairity_score'] < 0.99999] \n",
    "matches_df.sample(10)\n",
    "matches_df.sort_values(['similairity_score'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProcessedRef</th>\n",
       "      <th>SIMILAR_TITLE</th>\n",
       "      <th>similairity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>i̇lemin gürkan b status activity patterns cara...</td>\n",
       "      <td>status activity patterns caracal caracal carac...</td>\n",
       "      <td>0.995398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>i̇lemin gürkan b status activity patterns cara...</td>\n",
       "      <td>status activity patterns caracal caracal carac...</td>\n",
       "      <td>0.995398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>drones count gulls? minimal disturbance semiau...</td>\n",
       "      <td>drones count gulls? minimal disturbance semiau...</td>\n",
       "      <td>0.994427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>0.993995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7675</th>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>wolves modulate soil nutrient heterogeneity fo...</td>\n",
       "      <td>0.993995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9763</th>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>0.993516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9764</th>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>0.993516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9765</th>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>three novel methods estimate abundance unmarke...</td>\n",
       "      <td>0.993516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>0.992385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>remote infrared cameras used differentiate sma...</td>\n",
       "      <td>0.992385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>0.992324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>0.992324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>three critical factors affecting automated ima...</td>\n",
       "      <td>0.992324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>0.991660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>camera trapping: contemporary approach monitor...</td>\n",
       "      <td>0.991660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>“grabcut” - interactive foreground extraction ...</td>\n",
       "      <td>grabcut: interactive foreground extraction usi...</td>\n",
       "      <td>0.991386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>urbanization affects neophilia risk-taking bir...</td>\n",
       "      <td>urbanization affects neophilia risk-taking bir...</td>\n",
       "      <td>0.989681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>2012 državni zavod za zaštitu prirode zagreb g...</td>\n",
       "      <td>2010 državni zavod za zaštitu prirode zagreb g...</td>\n",
       "      <td>0.988848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>2010 državni zavod za zaštitu prirode zagreb g...</td>\n",
       "      <td>2012 državni zavod za zaštitu prirode zagreb g...</td>\n",
       "      <td>0.988848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>emerging technologies conserve biodiversity 20...</td>\n",
       "      <td>emerging technologies conserve biodiversity 20...</td>\n",
       "      <td>0.988594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>trophic scaling occupancy analysis reveals lio...</td>\n",
       "      <td>trophic scaling occupancy analysis reveals lio...</td>\n",
       "      <td>0.988119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>toad’s tongue breakfast: exploitation novel pr...</td>\n",
       "      <td>toad tongue breakfast: exploitation novel prey...</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>0.987555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>foraging ecology jaguar panthera onca puma pum...</td>\n",
       "      <td>0.987555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>high proportion male faeces jaguar populations...</td>\n",
       "      <td>high proportion male faeces jaguar populations...</td>\n",
       "      <td>0.986974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ProcessedRef  \\\n",
       "1940  i̇lemin gürkan b status activity patterns cara...   \n",
       "1939  i̇lemin gürkan b status activity patterns cara...   \n",
       "9169  drones count gulls? minimal disturbance semiau...   \n",
       "7674  wolves modulate soil nutrient heterogeneity fo...   \n",
       "7675  wolves modulate soil nutrient heterogeneity fo...   \n",
       "9763  three novel methods estimate abundance unmarke...   \n",
       "9764  three novel methods estimate abundance unmarke...   \n",
       "9765  three novel methods estimate abundance unmarke...   \n",
       "174   remote infrared cameras used differentiate sma...   \n",
       "3617  remote infrared cameras used differentiate sma...   \n",
       "3518  three critical factors affecting automated ima...   \n",
       "3520  three critical factors affecting automated ima...   \n",
       "3519  three critical factors affecting automated ima...   \n",
       "283   camera trapping: contemporary approach monitor...   \n",
       "3726  camera trapping: contemporary approach monitor...   \n",
       "1843  “grabcut” - interactive foreground extraction ...   \n",
       "4067  urbanization affects neophilia risk-taking bir...   \n",
       "1291  2012 državni zavod za zaštitu prirode zagreb g...   \n",
       "1278  2010 državni zavod za zaštitu prirode zagreb g...   \n",
       "3224  emerging technologies conserve biodiversity 20...   \n",
       "7195  trophic scaling occupancy analysis reveals lio...   \n",
       "7658  toad tongue breakfast: exploitation novel prey...   \n",
       "1406  toad’s tongue breakfast: exploitation novel pr...   \n",
       "1407  toad’s tongue breakfast: exploitation novel pr...   \n",
       "7657  toad tongue breakfast: exploitation novel prey...   \n",
       "8124  toad’s tongue breakfast: exploitation novel pr...   \n",
       "8125  toad’s tongue breakfast: exploitation novel pr...   \n",
       "5964  foraging ecology jaguar panthera onca puma pum...   \n",
       "6416  foraging ecology jaguar panthera onca puma pum...   \n",
       "5983  high proportion male faeces jaguar populations...   \n",
       "\n",
       "                                          SIMILAR_TITLE  similairity_score  \n",
       "1940  status activity patterns caracal caracal carac...           0.995398  \n",
       "1939  status activity patterns caracal caracal carac...           0.995398  \n",
       "9169  drones count gulls? minimal disturbance semiau...           0.994427  \n",
       "7674  wolves modulate soil nutrient heterogeneity fo...           0.993995  \n",
       "7675  wolves modulate soil nutrient heterogeneity fo...           0.993995  \n",
       "9763  three novel methods estimate abundance unmarke...           0.993516  \n",
       "9764  three novel methods estimate abundance unmarke...           0.993516  \n",
       "9765  three novel methods estimate abundance unmarke...           0.993516  \n",
       "174   remote infrared cameras used differentiate sma...           0.992385  \n",
       "3617  remote infrared cameras used differentiate sma...           0.992385  \n",
       "3518  three critical factors affecting automated ima...           0.992324  \n",
       "3520  three critical factors affecting automated ima...           0.992324  \n",
       "3519  three critical factors affecting automated ima...           0.992324  \n",
       "283   camera trapping: contemporary approach monitor...           0.991660  \n",
       "3726  camera trapping: contemporary approach monitor...           0.991660  \n",
       "1843  grabcut: interactive foreground extraction usi...           0.991386  \n",
       "4067  urbanization affects neophilia risk-taking bir...           0.989681  \n",
       "1291  2010 državni zavod za zaštitu prirode zagreb g...           0.988848  \n",
       "1278  2012 državni zavod za zaštitu prirode zagreb g...           0.988848  \n",
       "3224  emerging technologies conserve biodiversity 20...           0.988594  \n",
       "7195  trophic scaling occupancy analysis reveals lio...           0.988119  \n",
       "7658  toad’s tongue breakfast: exploitation novel pr...           0.987995  \n",
       "1406  toad tongue breakfast: exploitation novel prey...           0.987995  \n",
       "1407  toad tongue breakfast: exploitation novel prey...           0.987995  \n",
       "7657  toad’s tongue breakfast: exploitation novel pr...           0.987995  \n",
       "8124  toad tongue breakfast: exploitation novel prey...           0.987995  \n",
       "8125  toad tongue breakfast: exploitation novel prey...           0.987995  \n",
       "5964  foraging ecology jaguar panthera onca puma pum...           0.987555  \n",
       "6416  foraging ecology jaguar panthera onca puma pum...           0.987555  \n",
       "5983  high proportion male faeces jaguar populations...           0.986974  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe \n",
    "matches_df1 = get_matches_df(matches, refsDf['Title'], top=300000)\n",
    "matches_df1 = matches_df[matches_df['similairity_score'] > 0.5] \n",
    "matches_df1.sample(10)\n",
    "matches_df1.sort_values(['similairity_score'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df1 = get_matches_df(matches, refsDf['Title'], top=300000)\n",
    "matches_df = get_matches_df(matches, refsDf['ProcessedRef'], top=351103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches_df = pd.DataFrame()\n",
    "# matches_df = get_matches_df(matches, refsDf['CitingTitle'], top=10000)\n",
    "# # Remove all exact matches\n",
    "# matches_df = matches_df[matches_df['similairity_score'] < 0.99999] \n",
    "# matches_df.sample(10)\n",
    "# matches_df.sort_values(['similairity_score'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refsDf = pd.read_csv('citationNetworks/Data/SplitRefs.csv')\n",
    "#print(refsDf.head())\n",
    "#fuzz.ratio(refsDf[\"Title\"], refsDf[\"Reference\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    string = ftfy.fix_text(string)\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    string = string.lower()\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title()\n",
    "    string = re.sub(' +', ' ', string).strip()\n",
    "    string = ' '+ string +' '\n",
    "    string = re.sub(r'[,-./]\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearestN(query):\n",
    "  queryTFIDF_ = vectorizer.transform(query)\n",
    "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "  return distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "refsDf = pd.read_csv('citationNetworks/Data/SplitRefs.csv')\n",
    "#refsDf['ref_title'] = str(refsDf['ref_title'])\n",
    "refsDf = refsDf[['X','ID','Title', 'ref_title']]\n",
    "refsDf.set_axis(['Index', 'ID','Title', 'ref_title'], axis=1)\n",
    "# titlesAndIDs = refsDf[['ID','Title']]\n",
    "\n",
    "#titlesAndIDs.set_axis(['ID', 'ref_title'], axis=1)\n",
    "#refsDf = pd.concat([refsDf, titlesAndIDs])\n",
    "#refsDf.reset_index(inplace=True, drop=True)\n",
    "\n",
    "refsDf['ref_title'] = refsDf['ref_title'].astype(str)\n",
    "# titlesAndIDs['Title'] = titlesAndIDs['Title'].astype(str)\n",
    "\n",
    "cleanTitles = pd.read_csv('citationNetworks/Data/cleanTitles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanTitles = refsDf[['ID','Title']]\n",
    "cleanTitles['title'] = cleanTitles['title'].astype(str)\n",
    "# cleanTitles = cleanTitles.iloc[:, 0:6]\n",
    "cleanTitle = cleanTitles['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecorizing the data - this could take a few minutes for large datasets...\n",
      "Vecorizing completed...\n"
     ]
    }
   ],
   "source": [
    "# titlesAndIDs = titlesAndIDs.iloc[:, 0:6]\n",
    "# print(titlesAndIDs)\n",
    "# titlesAndIDs = titlesAndIDs['Title'].unique()\n",
    "# cleanTitles = titlesAndIDs['Title'].unique()\n",
    "print('Vecorizing the data - this could take a few minutes for large datasets...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(cleanTitle)\n",
    "print('Vecorizing completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "citedTitle = 'ref_title' #column to match against in the messy data\n",
    "uniqueCitedTitle = set(refsDf[citedTitle].values) # set used for increased performance###matching query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting nearest n...\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print('getting nearest n...')\n",
    "distances, indices = getNearestN(uniqueCitedTitle)\n",
    "t = time.time()-t1\n",
    "print(\"COMPLETED IN:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding matches...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2776\\1827683044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleanTitles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniqueCitedTitle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[0mmatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "uniqueCitedTitle = list(uniqueCitedTitle) #need to convert back to a list\n",
    "print('finding matches...')\n",
    "matches = []\n",
    "\n",
    "for i,j in enumerate(indices):\n",
    "  temp = [round(distances[i][0],2), cleanTitles.values[j][0][0], uniqueCitedTitle[i]]\n",
    "  matches.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building data frame...')  \n",
    "matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Origional name'])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# org_names = names['buyer'].unique()\n",
    "# vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "# tf_idf_matrix = vectorizer.fit_transform(org_names)\n",
    "\n",
    "# clean_org_names = pd.read_excel('Gov Orgs ONS.xlsx')\n",
    "# clean_org_names = clean_org_names.iloc[:, 0:6]\n",
    "# org_name_clean = clean_org_names['Institutions'].unique()\n",
    "\n",
    "\n",
    "# print('Vecorizing the data - this could take a few minutes for large datasets...')\n",
    "# vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "# tfidf = vectorizer.fit_transform(org_name_clean)\n",
    "# print('Vecorizing completed...')\n",
    "\n",
    "\n",
    "# nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "# org_column = 'buyer' #column to match against in the messy data\n",
    "# unique_org = set(names[org_column].values) # set used for increased performance\n",
    "\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# print('getting nearest n...')\n",
    "# distances, indices = getNearestN(unique_org)\n",
    "\n",
    "# t = time.time()-t1\n",
    "# print(\"COMPLETED IN:\", t)\n",
    "\n",
    "# unique_org = list(unique_org) #need to convert back to a list\n",
    "# print('finding matches...')\n",
    "# matches = []\n",
    "\n",
    "# for i,j in enumerate(indices):\n",
    "#   temp = [round(distances[i][0],2), clean_org_names.values[j][0][0],unique_org[i]]\n",
    "#   matches.append(temp)\n",
    "\n",
    "# print('Building data frame...')  \n",
    "# matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Origional name'])\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above basically works, however it is matching only within the single column (so just with titles of references). \n",
    "Potentially this can be solved by adding in the the citing papers titles to this column, with their actual IDs? \n",
    "Might be that from the Index column we can work back to getting the IDs linked back up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to unique \n",
    "# uniqueRefs = refsDf.drop_duplicates(subset=['ref_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(uniqueRefs)):\n",
    "#     title = uniqueRefs.iloc[i,6] # 6 or title\n",
    "#     refTitle = uniqueRefs.iloc[i,7] # 7 or ref title\n",
    "#     ID = uniqueRefs.iloc[i,4] # 4 or ID\n",
    "#     ratio = fuzz.ratio(title, refTitle)\n",
    "#     if ratio > 50:\n",
    "#         #append to a df with title, re_title, ID, ratio\n",
    "#         tmpDf = pd.DataFrame([[ID, title, refTitle, ratio]], columns=list('ID', 'Title', 'RefTitle', 'PercentMatch'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in uniqueRefs.iterrows():\n",
    "#     title = row['Title'] # 6 or title\n",
    "#     refTitle = row['ref_title'] # 7 or ref title\n",
    "#     ID = row['ID'] # 4 or ID\n",
    "#     ratio = fuzz.ratio(title, refTitle)\n",
    "#     # print(ratio)\n",
    "#     # if ratio > 50:\n",
    "#     #     #append to a df with title, re_title, ID, ratio\n",
    "#     #     tmpDf = pd.DataFrame([[ID, title, refTitle, ratio]], columns=list('ID', 'Title', 'RefTitle', 'PercentMatch'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_value = float(\"NaN\")\n",
    "# uniqueRefs = uniqueRefs.replace(\"\", nan_value)\n",
    "# uniqueRefs = uniqueRefs.dropna(subset=[\"ref_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniUniqueRefs = uniqueRefs.iloc[0:10]\n",
    "# titleDf = uniqueRefs = refsDf.drop_duplicates(subset=['Title'])#\n",
    "# #tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "# tmpDf = pd.DataFrame(columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID'))\n",
    "# columns = list(tmpDf)\n",
    "# newDF = []\n",
    "\n",
    "# for index, row in tqdm(miniUniqueRefs.iterrows()):\n",
    "#     title = row['Title'] # 6 or title\n",
    "#     refTitle = str(row['ref_title']) # 7 or ref title\n",
    "#     ID = row['ID'] # 4 or ID\n",
    "#     output = process.extractOne(refTitle, titleDf['Title'], scorer=fuzz.token_sort_ratio)\n",
    "#     # print(output)\n",
    "#     ratio = output[1]\n",
    "#     bestMatch = output[0]\n",
    "#     bestMatchID = output[2]\n",
    "#     values = [ID, title, refTitle, ratio, bestMatch, bestMatchID]\n",
    "#     zipped = zip(columns, values)\n",
    "#     dictionary = dict(zipped)\n",
    "#     newDF.append(dictionary)\n",
    "#     # tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "#     # tmpDf.columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID')\n",
    "#     # tmpDf.append(tmpDf)\n",
    "# print(tmpDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titleDf = uniqueRefs = refsDf.drop_duplicates(subset=['Title'])#\n",
    "# #tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "# tmpDf = pd.DataFrame(columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID'))\n",
    "# columns = list(tmpDf)\n",
    "# newDF = []\n",
    "\n",
    "# #with alive_bar(238148, force_tty=True) as bar:\n",
    "# for index, row in tqdm(uniqueRefs.iterrows()):\n",
    "#     title = row['Title'] # 6 or title\n",
    "#     refTitle = str(row['ref_title']) # 7 or ref title\n",
    "#     ID = row['ID'] # 4 or ID\n",
    "#     output = process.extractOne(refTitle, titleDf['Title'], scorer=fuzz.token_sort_ratio)\n",
    "#     # print(output)\n",
    "#     ratio = output[1]\n",
    "#     bestMatch = output[0]\n",
    "#     bestMatchID = output[2]\n",
    "#     values = [ID, title, refTitle, ratio, bestMatch, bestMatchID]\n",
    "#     zipped = zip(columns, values)\n",
    "#     dictionary = dict(zipped)\n",
    "#     newDF.append(dictionary)\n",
    "#     #tmpDf = pd.DataFrame([[ID, title, refTitle, ratio, bestMatch, bestMatchID]]) # add bits needed\n",
    "#     #tmpDf.columns=('ID', 'Title', 'RefTitle', 'PercentMatch', 'BestMatchTitle', 'BestMatchID')\n",
    "#     #tmpDf.append(tmpDf)\n",
    "# #bar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniUniqueRefs = uniqueRefs.iloc[0:10]\n",
    "# df0_names = list(miniUniqueRefs.ref_title.unique())\n",
    "# df1_names = list(uniqueRefs.ref_title.unique())\n",
    "# df2_names = list(uniqueRefs.Title.unique())\n",
    "# print(process.extractOne(str(df0_names), df2_names, scorer=fuzz.token_sort_ratio))\n",
    "# #print(process.extractOne(str(df1_names), df2_names, scorer=fuzz.token_sort_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def match_names(name, list_names, min_score=0):\n",
    "#     max_score = -1\n",
    "#     max_name = ''\n",
    "#     for x in list_names:\n",
    "#         score = fuzz.ratio(name, x)\n",
    "#         if (score > min_score) & (score > max_score):\n",
    "#             max_name = x\n",
    "#             max_score = score\n",
    "#     return (max_name, max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_names = list(uniqueRefs.ref_title.unique())\n",
    "# titlesList = list(uniqueRefs.Title.unique())\n",
    "# refsAsArray = uniqueRefs.to_numpy()\n",
    "# miniUniqueRefs = uniqueRefs.iloc[0:10]\n",
    "# miniArray = miniUniqueRefs.to_numpy()\n",
    "\n",
    "# print(process.extractOne(str(miniArray[:,5]), titlesList, scorer=fuzz.token_sort_ratio))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b0f069635f502c080d2c86df588aca401f45023c6eba452c7d287578147dabf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
